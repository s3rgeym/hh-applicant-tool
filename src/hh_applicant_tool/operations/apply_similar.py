from __future__ import annotations

import argparse
import json
import logging
import random
import string
import time
from pathlib import Path
from typing import TYPE_CHECKING, Any, Iterator

from .. import utils
from ..ai.base import AIError
from ..api import BadResponse, Redirect, datatypes
from ..api.datatypes import PaginatedItems, SearchVacancy
from ..api.errors import ApiError, LimitExceeded
from ..main import BaseNamespace, BaseOperation
from ..storage.repositories.errors import RepositoryError
from ..utils.datatypes import VacancyTestsData
from ..utils.string import (
    bool2str,
    rand_text,
    unescape_string,
)

if TYPE_CHECKING:
    from ..main import HHApplicantTool


logger = logging.getLogger(__package__)


class Namespace(BaseNamespace):
    resume_id: str | None
    message_list_path: Path
    ignore_employers: Path | None
    force_message: bool
    use_ai: bool
    first_prompt: str
    prompt: str
    order_by: str
    search: str
    schedule: str
    dry_run: bool
    # –ü–æ—à–ª–∏ –¥–æ–ø —Ñ–∏–ª—å—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –±—ã–ª–æ
    experience: str
    employment: list[str] | None
    area: list[str] | None
    metro: list[str] | None
    professional_role: list[str] | None
    industry: list[str] | None
    employer_id: list[str] | None
    excluded_employer_id: list[str] | None
    currency: str | None
    salary: int | None
    only_with_salary: bool
    label: list[str] | None
    period: int | None
    date_from: str | None
    date_to: str | None
    top_lat: float | None
    bottom_lat: float | None
    left_lng: float | None
    right_lng: float | None
    sort_point_lat: float | None
    sort_point_lng: float | None
    no_magic: bool
    premium: bool
    per_page: int
    total_pages: int
    excluded_terms: str | None


class Operation(BaseOperation):
    """–û—Ç–∫–ª–∏–∫–Ω—É—Ç—å—Å—è –Ω–∞ –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏."""

    __aliases__ = ("apply",)

    def setup_parser(self, parser: argparse.ArgumentParser) -> None:
        parser.add_argument("--resume-id", help="–ò–¥–µ–Ω—Ç–µ—Ñ–∏–∫–∞—Ç–æ—Ä —Ä–µ–∑—é–º–µ")
        parser.add_argument(
            "--search",
            help="–°—Ç—Ä–æ–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π, –Ω–∞–ø—Ä–∏–º–µ—Ä, '–º–æ—Å–∫–≤–∞ –±—É—Ö–≥–∞–ª—Ç–µ—Ä 100500'",  # noqa: E501
            type=str,
        )
        parser.add_argument(
            "-L",
            "--message-list-path",
            "--message-list",
            help="–ü—É—Ç—å –¥–æ —Ñ–∞–π–ª–∞, –≥–¥–µ —Ö—Ä–∞–Ω—è—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ—Ç–∫–ª–∏–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏. –ö–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏. –°–∏–º–≤–æ–ª—ã \\n –±—É–¥—É—Ç –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å—ã.",  # noqa: E501
            type=Path,
        )
        parser.add_argument(
            "-f",
            "--force-message",
            "--force",
            help="–í—Å–µ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç–∫–ª–∏–∫–µ",
            action=argparse.BooleanOptionalAction,
        )
        parser.add_argument(
            "--use-ai",
            "--ai",
            help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π",
            action=argparse.BooleanOptionalAction,
        )
        parser.add_argument(
            "--first-prompt",
            help="–ù–∞—á–∞–ª—å–Ω—ã–π –ø–æ–º–ø—Ç —á–∞—Ç–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∏—Å—å–º–∞",
            default="–ù–∞–ø–∏—à–∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ –¥–ª—è –æ—Ç–∫–ª–∏–∫–∞ –Ω–∞ —ç—Ç—É –≤–∞–∫–∞–Ω—Å–∏—é. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π placeholder'—ã, —Ç–≤–æ–π –æ—Ç–≤–µ—Ç –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏.",  # noqa: E501
        )
        parser.add_argument(
            "--prompt",
            help="–ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∏—Å—å–º–∞",
            default="–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ –Ω–µ –±–æ–ª–µ–µ 5-7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –æ—Ç –º–æ–µ–≥–æ –∏–º–µ–Ω–∏ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏",  # noqa: E501
        )
        parser.add_argument(
            "--total-pages",
            "--pages",
            help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ–∏—Å–∫–∞",  # noqa: E501
            default=20,
            type=int,
        )
        parser.add_argument(
            "--per-page",
            help="–°–∫–æ–ª—å–∫–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ",  # noqa: E501
            default=100,
            type=int,
        )
        parser.add_argument(
            "--dry-run",
            help="–ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –æ—Ç–∫–ª–∏–∫–∏, –∞ —Ç–æ–ª—å–∫–æ –≤—ã–≤–æ–¥–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é",
            action=argparse.BooleanOptionalAction,
        )

        # –î–∞–ª—å—à–µ –∏–¥—É—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∑–∞–ø—Ä–æ—Å–∞
        # –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π
        search_params_group = parser.add_argument_group(
            "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π",
            "–≠—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞–ø—Ä—è–º—É—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ñ–∏–ª—å—Ç—Ä–∞–º –ø–æ–∏—Å–∫–∞ HeadHunter API",
        )

        search_params_group.add_argument(
            "--order-by",
            help="–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π",
            choices=[
                "publication_time",
                "salary_desc",
                "salary_asc",
                "relevance",
                "distance",
            ],
            # default="relevance",
        )
        search_params_group.add_argument(
            "--experience",
            help="–£—Ä–æ–≤–µ–Ω—å –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã (noExperience, between1And3, between3And6, moreThan6)",
            type=str,
            default=None,
        )
        search_params_group.add_argument(
            "--schedule",
            help="–¢–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞ (fullDay, shift, flexible, remote, flyInFlyOut)",
            type=str,
        )
        search_params_group.add_argument(
            "--employment", nargs="+", help="–¢–∏–ø –∑–∞–Ω—è—Ç–æ—Å—Ç–∏"
        )
        search_params_group.add_argument(
            "--area", nargs="+", help="–†–µ–≥–∏–æ–Ω (area id)"
        )
        search_params_group.add_argument(
            "--metro", nargs="+", help="–°—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ (metro id)"
        )
        search_params_group.add_argument(
            "--professional-role", nargs="+", help="–ü—Ä–æ—Ñ. —Ä–æ–ª—å (id)"
        )
        search_params_group.add_argument(
            "--industry", nargs="+", help="–ò–Ω–¥—É—Å—Ç—Ä–∏—è (industry id)"
        )
        search_params_group.add_argument(
            "--employer-id", nargs="+", help="ID —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–π"
        )
        search_params_group.add_argument(
            "--excluded-employer-id", nargs="+", help="–ò—Å–∫–ª—é—á–∏—Ç—å —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–π"
        )
        search_params_group.add_argument(
            "--currency", help="–ö–æ–¥ –≤–∞–ª—é—Ç—ã (RUR, USD, EUR)"
        )
        search_params_group.add_argument(
            "--salary", type=int, help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞"
        )
        search_params_group.add_argument(
            "--only-with-salary",
            default=False,
            action=argparse.BooleanOptionalAction,
        )
        search_params_group.add_argument(
            "--label", nargs="+", help="–ú–µ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–π (label)"
        )
        search_params_group.add_argument(
            "--period", type=int, help="–ò—Å–∫–∞—Ç—å –≤–∞–∫–∞–Ω—Å–∏–∏ –∑–∞ N –¥–Ω–µ–π"
        )
        search_params_group.add_argument(
            "--date-from", help="–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å (YYYY-MM-DD)"
        )
        search_params_group.add_argument(
            "--date-to", help="–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø–æ (YYYY-MM-DD)"
        )
        search_params_group.add_argument(
            "--top-lat", type=float, help="–ì–µ–æ: –≤–µ—Ä—Ö–Ω—è—è —à–∏—Ä–æ—Ç–∞"
        )
        search_params_group.add_argument(
            "--bottom-lat", type=float, help="–ì–µ–æ: –Ω–∏–∂–Ω—è—è —à–∏—Ä–æ—Ç–∞"
        )
        search_params_group.add_argument(
            "--left-lng", type=float, help="–ì–µ–æ: –ª–µ–≤–∞—è –¥–æ–ª–≥–æ—Ç–∞"
        )
        search_params_group.add_argument(
            "--right-lng", type=float, help="–ì–µ–æ: –ø—Ä–∞–≤–∞—è –¥–æ–ª–≥–æ—Ç–∞"
        )
        search_params_group.add_argument(
            "--sort-point-lat",
            type=float,
            help="–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ lat –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é",
        )
        search_params_group.add_argument(
            "--sort-point-lng",
            type=float,
            help="–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ lng –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é",
        )
        search_params_group.add_argument(
            "--no-magic",
            action="store_true",
            help="–û—Ç–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ—Ä–∞–∑–±–æ—Ä —Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞",
        )
        search_params_group.add_argument(
            "--premium",
            default=False,
            action=argparse.BooleanOptionalAction,
            help="–¢–æ–ª—å–∫–æ –ø—Ä–µ–º–∏—É–º –≤–∞–∫–∞–Ω—Å–∏–∏",
        )
        search_params_group.add_argument(
            "--search-field",
            nargs="+",
            help="–ü–æ–ª—è –ø–æ–∏—Å–∫–∞ (name, company_name –∏ —Ç.–ø.)",
        )
        search_params_group.add_argument(
            "--excluded-terms",
            type=str,
            help="–ò—Å–∫–ª—é—á–∏—Ç—å –≤–∞–∫–∞–Ω—Å–∏–∏, –µ—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ snippet —Å–æ–¥–µ—Ä–∂–∏—Ç –ª—é–±—É—é –∏–∑ –ø–æ–¥—Å—Ç—Ä–æ–∫ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –Ω–∞–ø—Ä–∏–º–µ—Ä, junior, bitrix, –¥—Ä—É–∂–Ω—ã–π –∫–æ–ª–ª–µ–∫—Ç–∏–≤). –≠—Ç–æ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞",
        )

    def run(
        self,
        tool: HHApplicantTool,
    ) -> None:
        self.tool = tool
        self.api_client = tool.api_client
        args: Namespace = tool.args
        self.application_messages = self._get_application_messages(
            args.message_list_path
        )
        self.area = args.area
        self.bottom_lat = args.bottom_lat
        self.currency = args.currency
        self.date_from = args.date_from
        self.date_to = args.date_to
        self.dry_run = args.dry_run
        self.employer_id = args.employer_id
        self.employment = args.employment
        self.excluded_employer_id = args.excluded_employer_id
        self.experience = args.experience
        self.force_message = args.force_message
        self.industry = args.industry
        self.label = args.label
        self.left_lng = args.left_lng
        self.metro = args.metro
        self.no_magic = args.no_magic
        self.only_with_salary = args.only_with_salary
        self.order_by = args.order_by
        self.per_page = args.per_page
        self.period = args.period
        self.pre_prompt = args.prompt
        self.premium = args.premium
        self.professional_role = args.professional_role
        self.resume_id = args.resume_id
        self.right_lng = args.right_lng
        self.salary = args.salary
        self.schedule = args.schedule
        self.search = args.search
        self.search_field = args.search_field
        self.excluded_terms = self._parse_excluded_terms(args.excluded_terms)
        self.sort_point_lat = args.sort_point_lat
        self.sort_point_lng = args.sort_point_lng
        self.top_lat = args.top_lat
        self.total_pages = args.total_pages
        self.openai_chat = (
            tool.get_openai_chat(args.first_prompt) if args.use_ai else None
        )
        self._apply_similar()

    def _apply_similar(self) -> None:
        resumes: list[datatypes.Resume] = self.tool.get_resumes()
        try:
            self.tool.storage.resumes.save_batch(resumes)
        except RepositoryError as ex:
            logger.exception(ex)
        resumes = (
            list(filter(lambda x: x["id"] == self.resume_id, resumes))
            if self.resume_id
            else resumes
        )
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ
        resumes = list(
            filter(lambda x: x["status"]["id"] == "published", resumes)
        )
        if not resumes:
            logger.warning("–£ –≤–∞—Å –Ω–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—é–º–µ")
            return

        me: datatypes.User = self.tool.get_me()
        seen_employers = set()

        for resume in resumes:
            self._apply_resume(
                resume=resume,
                user=me,
                seen_employers=seen_employers,
            )

        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª–∏–∫–æ–≤
        # for neg in self.tool.get_negotiations():
        #     try:
        #         self.tool.storage.negotiations.save(neg)
        #     except RepositoryError as e:
        #         logger.warning(e)

        print("üìù –û—Ç–∫–ª–∏–∫–∏ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ —Ä–∞–∑–æ—Å–ª–∞–Ω—ã!")

    def _apply_resume(
        self,
        resume: datatypes.Resume,
        user: datatypes.User,
        seen_employers: set[str],
    ) -> None:
        logger.info(
            "–ù–∞—á–∏–Ω–∞—é —Ä–∞—Å—Å—ã–ª–∫—É –æ—Ç–∫–ª–∏–∫–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ: %s (%s)",
            resume["alternate_url"],
            resume["title"],
        )
        print("üöÄ –ù–∞—á–∏–Ω–∞—é —Ä–∞—Å—Å—ã–ª–∫—É –æ—Ç–∫–ª–∏–∫–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ:", resume["title"])

        placeholders = {
            "first_name": user.get("first_name") or "",
            "last_name": user.get("last_name") or "",
            "email": user.get("email") or "",
            "phone": user.get("phone") or "",
            "resume_title": resume.get("title") or "",
        }

        do_apply = True

        for vacancy in self._get_similar_vacancies(resume_id=resume["id"]):
            try:
                employer = vacancy.get("employer", {})

                message_placeholders = {
                    "vacancy_name": vacancy.get("name", ""),
                    "employer_name": employer.get("name", ""),
                    **placeholders,
                }

                storage = self.tool.storage

                try:
                    storage.vacancies.save(vacancy)
                except RepositoryError as ex:
                    logger.debug(ex)

                # –ü–æ —Ñ–∞–∫—Ç—É –∫–æ–Ω—Ç–∞–∫—Ç—ã –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –∑–¥–µ—Å—å?!
                if vacancy.get("contacts"):
                    logger.debug(
                        f"–ù–∞–π–¥–µ–Ω—ã –∫–æ–Ω—Ç–∞–∫—Ç—ã –≤ –≤–∞–∫–∞–Ω—Å–∏–∏: {vacancy['alternate_url']}"
                    )

                    try:
                        # logger.debug(vacancy)
                        storage.vacancy_contacts.save(vacancy)
                    except RepositoryError as ex:
                        logger.exception(ex)

                    employer_id = employer.get("id")
                    if employer_id and employer_id not in seen_employers:
                        employer_profile: datatypes.Employer = (
                            self.api_client.get(f"/employers/{employer_id}")
                        )

                        try:
                            storage.employers.save(employer_profile)
                        except RepositoryError as ex:
                            logger.exception(ex)

                if not do_apply:
                    continue

                vacancy_id = vacancy["id"]
                relations = vacancy.get("relations", [])

                if relations:
                    logger.debug(
                        "–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏—é —Å –æ—Ç–∫–ª–∏–∫–æ–º: %s",
                        vacancy["alternate_url"],
                    )
                    if "got_rejection" in relations:
                        logger.debug(
                            "–í—ã –ø–æ–ª—É—á–∏–ª–∏ –æ—Ç–∫–∞–∑ –æ—Ç %s",
                            vacancy["alternate_url"],
                        )
                        print("‚õî –ü—Ä–∏—à–µ–ª –æ—Ç–∫–∞–∑ –æ—Ç", vacancy["alternate_url"])
                    continue

                if vacancy.get("archived"):
                    logger.debug(
                        "–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏—é –≤ –∞—Ä—Ö–∏–≤–µ: %s",
                        vacancy["alternate_url"],
                    )
                    continue

                if redirect_url := vacancy.get("response_url"):
                    logger.debug(
                        "–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏—é %s —Å –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º: %s",
                        vacancy["alternate_url"],
                        redirect_url,
                    )
                    continue

                if self._is_excluded(vacancy):
                    logger.warning(
                        "–í–∞–∫–∞–Ω—Å–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏—è: %s",
                        vacancy["alternate_url"],
                    )
                    continue

                response_letter = ""

                if self.force_message or vacancy.get(
                    "response_letter_required"
                ):
                    if self.openai_chat:
                        msg = self.pre_prompt + "\n\n"
                        msg += (
                            "–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏: "
                            + message_placeholders["vacancy_name"]
                        )
                        msg += (
                            "–ú–æ–µ —Ä–µ–∑—é–º–µ:" + message_placeholders["resume_title"]
                        )
                        logger.debug("prompt: %s", msg)
                        response_letter = self.openai_chat.send_message(msg)
                    else:
                        response_letter = unescape_string(
                            rand_text(random.choice(self.application_messages))
                            % message_placeholders
                        )

                    logger.debug(response_letter)

                logger.debug(
                    "–ü—Ä–æ–±—É–µ–º –æ—Ç–∫–ª–∏–∫–Ω—É—Ç—å—Å—è –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é: %s",
                    vacancy["alternate_url"],
                )

                if vacancy.get("has_test"):
                    logger.debug(
                        "–†–µ—à–∞–µ–º —Ç–µ—Å—Ç: %s",
                        vacancy["alternate_url"],
                    )

                    try:
                        if not self.dry_run:
                            result = self._solve_vacancy_test(
                                vacancy_id=vacancy["id"],
                                resume_hash=resume["id"],
                                letter=response_letter,
                            )
                            if result.get("success") == "true":
                                print(
                                    "üì® –û—Ç–ø—Ä–∞–≤–∏–ª–∏ –æ—Ç–∫–ª–∏–∫ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é —Å —Ç–µ—Å—Ç–æ–º",
                                    vacancy["alternate_url"],
                                )
                            else:
                                err = result.get("error")

                                if err == "negotiations-limit-exceeded":
                                    do_apply = False
                                    logger.warning("–î–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞ –Ω–∞ –æ—Ç–∫–ª–∏–∫–∏")
                                else:
                                    logger.error(
                                        f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫–ª–∏–∫–µ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é —Å —Ç–µ—Å—Ç–æ–º: {vacancy['alternate_url']} - {err}"
                                    )
                    except Exception as ex:
                        logger.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {ex}")

                else:
                    params = {
                        "resume_id": resume["id"],
                        "vacancy_id": vacancy_id,
                        "message": response_letter,
                    }
                    try:
                        if not self.dry_run:
                            res = self.api_client.post(
                                "/negotiations",
                                params,
                                delay=random.uniform(1, 3),
                            )
                            assert res == {}
                            print(
                                "üì® –û—Ç–ø—Ä–∞–≤–∏–ª–∏ –æ—Ç–∫–ª–∏–∫ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é",
                                vacancy["alternate_url"],
                            )
                    except Redirect:
                        logger.warning(
                            f"–ò–≥–Ω–æ—Ä–∏—Ä—É—é –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ —Ñ–æ—Ä–º—É: {vacancy['alternate_url']}"  # noqa: E501
                        )
            except LimitExceeded:
                do_apply = False
                logger.warning("–î–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞ –Ω–∞ –æ—Ç–∫–ª–∏–∫–∏")
            except ApiError as ex:
                logger.warning(ex)
            except (BadResponse, AIError) as ex:
                logger.error(ex)

        logger.info(
            "–ó–∞–∫–æ–Ω—á–∏–ª–∏ —Ä–∞—Å—Å—ã–ª–∫—É –æ—Ç–∫–ª–∏–∫–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ: %s (%s)",
            resume["alternate_url"],
            resume["title"],
        )
        print("‚úÖÔ∏è –ó–∞–∫–æ–Ω—á–∏–ª–∏ —Ä–∞—Å—Å—ã–ª–∫—É –æ—Ç–∫–ª–∏–∫–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ:", resume["title"])

    def _get_vacancy_tests(
        self, response_url: str
    ) -> tuple[VacancyTestsData, str]:
        """–ü–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤ –∏ XSRF —Ç–æ–∫–µ–Ω —á–µ—Ä–µ–∑ —Å–ø–ª–∏—Ç—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏—Å–∫–ª—é—á–µ–Ω–∏–π ü§ñ"""
        r = self.tool.session.get(response_url)

        try:
            # –ü–∞—Ä—Å–∏–º —Ç–µ—Å—Ç—ã –∏ —Ç–æ–∫–µ–Ω —á–µ—Ä–µ–∑ —Å–ø–ª–∏—Ç—ã
            tests = utils.json.loads(
                r.text.split(',"vacancyTests":')[1].split(',"counters":')[0],
                strict=False,
            )
            xsrf_token = r.text.split('"xsrfToken":"')[1].split('"')[0]

            return tests, xsrf_token

        except (IndexError, json.JSONDecodeError):
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ HH")

    def _solve_vacancy_test(
        self,
        vacancy_id: str | int,
        resume_hash: str,
        letter: str = "",
    ) -> dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ—Å—Ç, –∂–¥–µ—Ç –ø–∞—É–∑—É –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–∫–ª–∏–∫."""
        response_url = f"https://hh.ru/applicant/vacancy_response?vacancyId={vacancy_id}&startedWithQuestion=false&hhtmFrom=vacancy"

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–∞ –∏ —Ç–æ–∫–µ–Ω
        tests, xsrf_token = self._get_vacancy_tests(response_url)

        try:
            test_data = tests[str(vacancy_id)]
        except KeyError:
            raise ValueError(
                "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–∞ –¥–ª—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–∏."
            )

        logger.debug(f"{test_data = }")

        payload: dict[str, Any] = {
            "_xsrf": xsrf_token,
            "uidPk": test_data["uidPk"],
            "guid": test_data["guid"],
            "startTime": test_data["startTime"],
            "testRequired": test_data["required"],
            "vacancy_id": vacancy_id,
            "resume_hash": resume_hash,
            "ignore_postponed": "true",
            "incomplete": "false",
            "mark_applicant_visible_in_vacancy_country": "false",
            "country_ids": "[]",
            "lux": "true",
            "withoutTest": "no",
            "letter": letter,
        }

        for task in test_data["tasks"]:
            field_name = f"task_{task['id']}"
            solutions = task.get("candidateSolutions", [])

            if solutions:
                payload[field_name] = random.choice(solutions)["id"]
            else:
                # –†–∞–Ω–¥–æ–º–Ω—ã–µ —ç–º–æ–¥–∂–∏
                # payload[f"{field_name}_text"] = "".join(
                #     chr(random.randint(0x1F300, 0x1F64F))
                #     for _ in range(random.randint(3, 15))
                # )
                payload[f"{field_name}_text"] = random.choice(
                    string.ascii_lowercase + string.digits
                ) * random.randint(5, 35)

        logger.debug(f"{payload = }")

        # –û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π (float)
        time.sleep(random.uniform(2.0, 3.0))

        response = self.tool.session.post(
            "https://hh.ru/applicant/vacancy_response/popup",
            data=payload,
            headers={
                "Referer": response_url,
                # x-gib-fgsscgib-w-hh –∏ x-gib-gsscgib-w-hh –≤—Ä–æ–¥–µ –≤ –∫—É–∫–∞—Ö
                # –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –∏ –Ω–µ –Ω—É–∂–Ω—ã
                "X-Hhtmfrom": "vacancy",
                "X-Hhtmsource": "vacancy_response",
                "X-Requested-With": "XMLHttpRequest",
                "X-Xsrftoken": xsrf_token,
            },
        )

        logger.debug(
            "%s %s %d",
            response.request.method,
            response.url,
            response.status_code,
        )

        data = response.json()
        # logger.debug(data)

        return data

    def _get_search_params(self, page: int) -> dict:
        params = {
            "page": page,
            "per_page": self.per_page,
        }
        if self.order_by:
            params |= {"order_by": self.order_by}
        if self.search:
            params["text"] = self.search
        if self.schedule:
            params["schedule"] = self.schedule
        if self.experience:
            params["experience"] = self.experience
        if self.currency:
            params["currency"] = self.currency
        if self.salary:
            params["salary"] = self.salary
        if self.period:
            params["period"] = self.period
        if self.date_from:
            params["date_from"] = self.date_from
        if self.date_to:
            params["date_to"] = self.date_to
        if self.top_lat:
            params["top_lat"] = self.top_lat
        if self.bottom_lat:
            params["bottom_lat"] = self.bottom_lat
        if self.left_lng:
            params["left_lng"] = self.left_lng
        if self.right_lng:
            params["right_lng"] = self.right_lng
        if self.sort_point_lat:
            params["sort_point_lat"] = self.sort_point_lat
        if self.sort_point_lng:
            params["sort_point_lng"] = self.sort_point_lng
        if self.search_field:
            params["search_field"] = list(self.search_field)
        if self.employment:
            params["employment"] = list(self.employment)
        if self.area:
            params["area"] = list(self.area)
        if self.metro:
            params["metro"] = list(self.metro)
        if self.professional_role:
            params["professional_role"] = list(self.professional_role)
        if self.industry:
            params["industry"] = list(self.industry)
        if self.employer_id:
            params["employer_id"] = list(self.employer_id)
        if self.excluded_employer_id:
            params["excluded_employer_id"] = list(self.excluded_employer_id)
        if self.label:
            params["label"] = list(self.label)
        if self.only_with_salary:
            params["only_with_salary"] = bool2str(self.only_with_salary)
        # if self.clusters:
        #     params["clusters"] = bool2str(self.clusters)
        if self.no_magic:
            params["no_magic"] = bool2str(self.no_magic)
        if self.premium:
            params["premium"] = bool2str(self.premium)
        # if self.responses_count_enabled is not None:
        #     params["responses_count_enabled"] = bool2str(self.responses_count_enabled)

        return params

    def _get_similar_vacancies(self, resume_id: str) -> Iterator[SearchVacancy]:
        for page in range(self.total_pages):
            logger.debug(
                f"–ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {page + 1}"
            )
            params = self._get_search_params(page)
            res: PaginatedItems[SearchVacancy] = self.api_client.get(
                f"/resumes/{resume_id}/similar_vacancies",
                params,
            )

            logger.debug(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {res['found']}")

            if not res["items"]:
                return

            yield from res["items"]

            if page >= res["pages"] - 1:
                return

    @staticmethod
    def _parse_excluded_terms(excluded_terms: str | None) -> list[str]:
        if not excluded_terms:
            return []
        return [
            x.strip() for x in excluded_terms.lower().split(",") if x.strip()
        ]

    def _is_excluded(self, vacancy: SearchVacancy) -> bool:
        snippet = vacancy.get("snippet") or {}
        combined = " ".join(
            [
                vacancy.get("name") or "",
                snippet.get("requirement") or "",
                snippet.get("responsibility") or "",
            ]
        ).lower()

        return any(v in combined for v in self.excluded_terms)

    def _get_application_messages(self, path: Path | None) -> list[str]:
        return (
            list(
                filter(
                    None,
                    map(
                        str.strip,
                        path.open(encoding="utf-8", errors="replace"),
                    ),
                )
            )
            if path
            else [
                "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –º–µ–Ω—è –∑–æ–≤—É—Ç %(first_name)s. {–ú–µ–Ω—è –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–ª–∞|–ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å} –≤–∞—à–∞ –≤–∞–∫–∞–Ω—Å–∏—è ¬´%(vacancy_name)s¬ª. –•–æ—Ç–µ–ª–æ—Å—å –±—ã {–ø–æ–æ–±—â–∞—Ç—å—Å—è|–∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã} –æ –Ω–µ–π.",
                "{–ü—Ä–æ—à—É|–ü—Ä–µ–¥–ª–∞–≥–∞—é} —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å {–º–æ—é –∫–∞–Ω–¥–∏–¥–∞—Ç—É—Ä—É|–º–æ–µ —Ä–µ–∑—é–º–µ ¬´%(resume_title)s¬ª} –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é ¬´%(vacancy_name)s¬ª. –° —É–≤–∞–∂–µ–Ω–∏–µ–º, %(first_name)s.",  # noqa: E501
            ]
        )
